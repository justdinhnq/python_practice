{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c498389f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-06T04:37:53.616307Z",
     "iopub.status.busy": "2022-04-06T04:37:53.615747Z",
     "iopub.status.idle": "2022-04-06T04:37:53.619601Z",
     "shell.execute_reply": "2022-04-06T04:37:53.618996Z",
     "shell.execute_reply.started": "2022-04-06T02:49:10.757834Z"
    },
    "papermill": {
     "duration": 0.018518,
     "end_time": "2022-04-06T04:37:53.619740",
     "exception": false,
     "start_time": "2022-04-06T04:37:53.601222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27939b56",
   "metadata": {
    "papermill": {
     "duration": 0.005262,
     "end_time": "2022-04-06T04:37:53.631473",
     "exception": false,
     "start_time": "2022-04-06T04:37:53.626211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3 techniques of feature selection methods:\n",
    "1. Filter methods(6)\n",
    "    - missing values ratio\n",
    "    - variance threshold\n",
    "    - correlation coefficient\n",
    "    - chi-square test of independent (for categorical data)\n",
    "    - mutual info (for both regression & classification)\n",
    "    - analysis of variance (ANOVA)\n",
    "2. Wrapper methods\n",
    "    - sequential feature selection\n",
    "    - recursive feature elimination (RFE)\n",
    "3. Embedded methods\n",
    "    - L1 (LASSO) regularization\n",
    "    - Tree model (for regression & classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e106739",
   "metadata": {
    "papermill": {
     "duration": 0.005148,
     "end_time": "2022-04-06T04:37:53.642176",
     "exception": false,
     "start_time": "2022-04-06T04:37:53.637028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### With filter methods, \n",
    "\n",
    "we primarily apply a statistical measure that suits our data to assign each feature column a calculated score. Based on that score, it'll be decided whether that feature will be kept or removed from our predictive model\n",
    "\n",
    "Pros and cons:\n",
    "- Pros: computationally inexpensive + best for eliminating redundant irrelevant features\n",
    "- Cons: don't take feature correlations into consideration since they work independently on each feature\n",
    "\n",
    "2 types of filter methods:\n",
    "1. univariate filter: work on ranking a single feature \n",
    "2. multivariate filer: evaluate the entire feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23776427",
   "metadata": {
    "papermill": {
     "duration": 0.005134,
     "end_time": "2022-04-06T04:37:53.652693",
     "exception": false,
     "start_time": "2022-04-06T04:37:53.647559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### In wrapper methods,\n",
    "\n",
    "we primarily choose a subset of features and train them using a ML algorithm. Based on the inferences from this model, we employ a search strategy to look through the space of possible feature subsets and decide which feature to add or remove for the next model development.\n",
    "\n",
    "This loop continues until the model performance no longer changes with the desired count of features. (k_features)\n",
    "\n",
    "Pros and cons:\n",
    "- Pros: takes care of the interactions between features, ultimately finding the optimal subset of features for your model with the lowest possible error.\n",
    "- Cons: computationally expensive as the features increase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b5f7e3",
   "metadata": {
    "papermill": {
     "duration": 0.005345,
     "end_time": "2022-04-06T04:37:53.663667",
     "exception": false,
     "start_time": "2022-04-06T04:37:53.658322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### In embedded methods,\n",
    "\n",
    "combining the functionalities of both Filter and Wrapper methods\n",
    "\n",
    "Embedded methods perform feature selection during the process of training (which is why they're called embedded)\n",
    "\n",
    "**Upside:** the computational speed is as good as of filter methods + better accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.82808,
   "end_time": "2022-04-06T04:37:56.343582",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-06T04:37:42.515502",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
